{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = [3400,30] #redshift, distance cutoff for box that will be used  \n",
    "\n",
    "#importing simulation box \n",
    "data = np.load(\"C:/Users/yaras/Documents/Research/Feldman/MLdata/ML100-error4.npy\")\n",
    "\n",
    "#full box \n",
    "redshift0 = data[:,0] \n",
    "distance0 = data[:,2]\n",
    "distance_mod0 = data[:,1]\n",
    "velocity0 = data[:,3]\n",
    "\n",
    "#taking full box and redefining it with cutoffs \n",
    "inds = np.where(redshift0 <= rs[0])\n",
    "redshift = redshift0[inds]\n",
    "distance = distance0[inds]\n",
    "distance_mod = distance_mod0[inds]\n",
    "velocity = velocity0[inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(redshift)\n",
    "# print(redshift.shape)\n",
    "# print(distance)\n",
    "# print(distance_mod)\n",
    "# print(velocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # testing stuff\n",
    "# # trying to really figure out how axes work\n",
    "\n",
    "# a = np.arange(0,8).reshape(2,2,2)\n",
    "# b = np.arange(12,20).reshape(2,2,2)\n",
    "\n",
    "# # print(a)\n",
    "# # print(b)\n",
    "\n",
    "# print(np.stack((a,b)).shape)\n",
    "# print(np.stack((a,b)))\n",
    "# print(np.stack((a,b), axis=1))\n",
    "# print(np.stack((a,b), axis=2))\n",
    "# print(np.stack((a,b), axis=3))\n",
    "# print(np.stack((a,b), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making inputs and outputs into cohesive arrays \n",
    "X = np.stack([redshift / np.max(np.abs(redshift)), \\\n",
    "        distance_mod / np.max(np.abs(distance_mod))], \\\n",
    "        axis=-1)\n",
    "y = np.stack([velocity / np.max(np.abs(velocity)), \\\n",
    "        distance / np.max(np.abs(distance))], \\\n",
    "        axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X)\n",
    "# print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data into train and test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this model is a neural net\n",
    "#characterized by ALL TANH ACTIVATION FUNCTIONS, AND AUTOMATED LEARNING RATES WITH LOOP \n",
    "#you can customize how many layers you have, the number of nodes in them, \n",
    "#and the activation function \n",
    "model8 = keras.models.Sequential()\n",
    "model8.add(keras.layers.InputLayer(input_shape=[2]))\n",
    "model8.add(keras.layers.Dense(25, activation='tanh'))\n",
    "model8.add(keras.layers.Dense(50, activation='tanh'))\n",
    "model8.add(keras.layers.Dense(100, activation='tanh'))\n",
    "model8.add(keras.layers.Dense(50, activation='tanh'))\n",
    "model8.add(keras.layers.Dense(25, activation='tanh'))\n",
    "model8.add(keras.layers.Dense(2, activation='tanh'))\n",
    "\n",
    "#starting off with an optimizer that has a certain learning rate \n",
    "optimizer = keras.optimizers.Adam()\n",
    "\n",
    "#finalizing model and choosing loss function \n",
    "model8.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "\n",
    "#initial conditions\n",
    "# learningrate = 0.001\n",
    "epoch_step = 4 #epochs will go in sets of 4 before changing \n",
    "epoch_lower = 0 #initial \n",
    "epoch_upper = epoch_step #initial \n",
    "threshold = 0.005 #threshold of loss difference between epochs \n",
    "while epoch_upper < 21: #adding on 20 epochs \n",
    "    a = model8.fit(X_train, y_train, initial_epoch=epoch_lower, epochs=epoch_upper)\n",
    "    print(a.history['loss']) #this is how  you get the loss when the model above is fit with the given lr\n",
    "    epoch_lower += epoch_step\n",
    "    epoch_upper += epoch_step  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_vel(y_pred,y_test,rs,distance):\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    fig.set_figheight(8) \n",
    "    fig.set_figwidth(20) \n",
    "    m = np.where(y_pred[:,1]*np.max(np.abs(distance)) <= rs[1])\n",
    "    predvel = y_pred[:,0][m]#*1.2\n",
    "    preddist = y_pred[:,1][m]\n",
    "    \n",
    "    #plotting true vs true distance and predicted distances along line \n",
    "    a = fig.add_subplot(1,2,1)\n",
    "    plt.plot(y_test[:,1][m],preddist,'.')\n",
    "    plt.plot(y_test[:,1][m],y_test[:,1][m])\n",
    "    plt.title('Predicted vs True Distances')\n",
    "    \n",
    "    #same as above but for velocity \n",
    "    a = fig.add_subplot(1,2,2)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(y_test[:,0][m], predvel, '.')\n",
    "    plt.plot(y_test[:,0][m], y_test[:,0][m])\n",
    "    plt.title('Predicted vs True Velocities')\n",
    "    \n",
    "def hist_resids(y_pred,y_test,rs,distance):\n",
    "    m = np.where(y_pred[:,1]*np.max(np.abs(distance)) <= rs[1])\n",
    "    \n",
    "    predvel = y_pred[:,0][m]\n",
    "    preddist = y_pred[:,1][m]\n",
    "    \n",
    "    #histogram of velocity residuals \n",
    "    vel_resids = (y_test[:,0][m] - predvel)*np.max(np.abs(velocity))\n",
    "    avg = np.mean(vel_resids)\n",
    "    a = plt.hist(vel_resids,bins=50)\n",
    "    plt.axvline(vel_resids.mean(), color='k', linestyle='dashed', linewidth=1)\n",
    "    plt.title('Velocity Residuals' + 'Avg =' + str(avg))\n",
    "    mean = np.mean(vel_resids)\n",
    "    variance = np.var(vel_resids)\n",
    "    sigma = np.sqrt(variance)\n",
    "    zx = np.linspace(min(vel_resids), max(vel_resids), 100)\n",
    "    dx = a[1][1] - a[1][0]\n",
    "    scale = len(vel_resids)*dx\n",
    "    plt.plot(zx, norm.pdf(zx, mean, sigma)*scale)\n",
    "    plt.text(-1200,700,'sigma ='+str(sigma),color='black')\n",
    "    plt.text(-1200,450,'mean ='+str(mean),color='black')\n",
    "\n",
    "    plt.savefig('NN Velocity Residuals',transparent=True)\n",
    "    plt.show()\n",
    "    \n",
    "    #velocity residuals plot \n",
    "    plt.plot(y_pred[:,1][m]*np.max(np.abs(distance)),vel_resids,'bo',markersize='.5')\n",
    "    plt.axhline(0, color='k', linestyle='dashed', linewidth=1)\n",
    "    plt.title(str(rs))\n",
    "    plt.xlabel('PREDICTED distance')\n",
    "    plt.ylabel('Velocity Residual')\n",
    "    #plt.ylim(-800,800)\n",
    "    plt.savefig('RF Residual Dist ' + str(rs),transparent=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Automated LR, all tanh \n",
    "preds = model8.predict(X_test)\n",
    "dist_vel(preds,y_test,rs,distance)\n",
    "plt.show()\n",
    "hist_resids(preds,y_test,rs,distance)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6038a1b420e1c960d5a71fceb90c2902e154518be2efe0b3c15ee4b8a34c8ba"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
